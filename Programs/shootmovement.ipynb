{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d06358c0-1062-4dbd-8c14-12f8c3448593",
   "metadata": {},
   "source": [
    "# <font color='black'> Shoot movements as a feature for detecting stress</font>\n",
    "This research aimed to detect and measure leaf movement and displacement of A. thaliana seedlings using the Lucas-Kanade optical flow method. It estimated the leaf expansion and movement from a vector field obtained from consecutive images of the plants taken from the top view.<br/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bddee72-1324-42cf-bd44-32a9a9e34d1d",
   "metadata": {},
   "source": [
    "### Import &rarr; Python modules\n",
    "The Shoot movements program needs multiple Python modules to run properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70aa87-9389-4c5c-81c9-87b4cd9e6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.fft import fft, fftfreq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3180a6e5-4d93-44b8-89d8-2a43cda31cac",
   "metadata": {},
   "source": [
    "### Import &rarr; User modules\n",
    "We created our own modules to organize the code and follow the object oriented programming philosophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fa631-da8b-416b-a091-5530a67e622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "import imalgo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be0a0722-7174-461e-9647-8bfc043ac036",
   "metadata": {},
   "source": [
    "### Variable declaration \n",
    "Define the Experiment & camera ID details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04668c8d-ce4c-4c9c-a42b-b6257874d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expID, daySowing, cam = \"exp09\", \"2018-09-11-00-00\", \"cam03\"  # Color Constancy\n",
    "dayTreat = \"2018-10-02-17-30\"\n",
    "dateSowing = datetime.datetime.strptime(daySowing, \"%Y-%m-%d-%H-%M\")\n",
    "dateTreat = datetime.datetime.strptime(dayTreat, \"%Y-%m-%d-%H-%M\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbc1b7ae-0dc7-4ea6-91e8-1263a8174bd3",
   "metadata": {},
   "source": [
    "### Directories \n",
    "Define the folder paths where is located the green fabric dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb47030-eefd-4284-b94b-8b4203f5c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirCurrent = os.getcwd()\n",
    "dirParent = os.path.abspath(os.path.join(dirCurrent, os.pardir)) \n",
    "coor_path = os.path.join(dirParent, 'Datasets', expID, expID + \"_coord_\" + cam + \".csv\")\n",
    "folder_images   = os.path.join(dirParent, 'Datasets', expID, expID + '_' + 'img')\n",
    "csv_folder = os.path.join(dirParent, 'Datasets', expID, expID + '_' + \"csv_measures\")\n",
    "\n",
    "\n",
    "if not os.path.exists(csv_folder):\n",
    "    os.makedirs(csv_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "863eaf22-8962-44ca-919d-144a9c138dd3",
   "metadata": {},
   "source": [
    "### Read files & set Variables\n",
    "Parameters for the image prespective and lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93697344-f556-41df-8500-39500ecd94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = np.finfo(float).eps\n",
    "coor_df = pd.read_csv(coor_path)\n",
    "outliers = coor_df.loc[coor_df[\"outlier\"] == \"yes\", \"position\"].tolist()\n",
    "\n",
    "img_folders = [x for x in os.listdir(folder_images) if x != \".DS_Store\"]\n",
    "\n",
    "df_folders = pd.DataFrame(img_folders, columns=[\"folderName\"])\n",
    "df_folders[[\"position\", \"name\", \"treatment\"]] = df_folders[\"folderName\"].str.split('_',expand=True)\n",
    "\n",
    "df_filter = df_folders[~df_folders[\"position\"].isin(outliers)]\n",
    "df_filter.reset_index(drop=True, inplace=True)\n",
    "\n",
    "winSiz = 295\n",
    "step = 1\n",
    "vec_ang = np.arange(-180, 180 + step, step, dtype=int)\n",
    "new_cols = [\"area_prev\", \"area_next\", \"mag_mean\", \"mag_sum\"] + np.copy(\n",
    "    vec_ang\n",
    ").astype(str).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcb88fbb",
   "metadata": {},
   "source": [
    "### Good features and Lucas-Kanade optical flow parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cced196",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_params = dict(\n",
    "    maxCorners=1000, qualityLevel=0.3, minDistance=3, blockSize=3)\n",
    "\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),\n",
    "    maxLevel=2,\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1b17e21",
   "metadata": {},
   "source": [
    "### Optical flow calculation between consecutive images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d595a8-d6fa-4fbe-9a1a-0f54169433cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for cnt1 in range(40, 41):\n",
    "for cnt1 in range(len(df_filter)):\n",
    "    df_output = pd.DataFrame()\n",
    "    folder_name, posn, name, treat = df_filter.loc[cnt1, :].values\n",
    "    dirImgs = os.path.join(folder_images, folder_name)\n",
    "    list_images = [x for x in os.listdir(dirImgs) if (x[-3:]) == \"png\"]\n",
    "    \n",
    "    print(cnt1, folder_name, posn, name, treat)\n",
    "\n",
    "    df_main = pd.DataFrame(list_images, columns=[\"filename\"])\n",
    "    df_main[\"date\"] = df_main[\"filename\"].apply(\n",
    "        lambda x: datetime.datetime.strptime(x[6:-4], \"%Y-%m-%d-%H-%M-%S\")\n",
    "    )\n",
    "    df_main[\"DAS\"] = df_main[\"date\"].apply(lambda x: (x - dateSowing).days)\n",
    "    days = df_main.loc[:, \"DAS\"].unique()\n",
    "    \n",
    "    for das in days:\n",
    "        \n",
    "        # if das != 19: continue\n",
    "\n",
    "        df_das = df_main[(df_main[\"DAS\"] == das)]\n",
    "        df_das = df_das.dropna(axis=0)\n",
    "        df_das.reset_index(drop=True, inplace=True)\n",
    "        df_das = df_das.reindex(columns=df_das.columns.tolist() + new_cols)\n",
    "        \n",
    "        path_prev = os.path.join(dirImgs, df_das.loc[0, \"filename\"])\n",
    "        img_prev, gray_prev, area_prev = imalgo.gray_img(winSiz, path_prev)\n",
    "        p0 = cv2.goodFeaturesToTrack(gray_prev, mask=None, **feature_params)\n",
    "\n",
    "        for cnt3 in range(len(df_das)-1):\n",
    "            path_next = os.path.join(dirImgs, df_das.loc[cnt3 + 1, \"filename\"])\n",
    "            img_next, gray_next, area_next = imalgo.gray_img(winSiz, path_next)\n",
    "                       \n",
    "            if len(gray_next)== 0 : \n",
    "                df_das.loc[cnt3, \"area_next\"] = area_prev\n",
    "                df_das.loc[cnt3, \"area_prev\"] = area_prev\n",
    "                df_das.loc[cnt3, \"mag_mean\"] = mag_mean\n",
    "                df_das.loc[cnt3, \"mag_sum\"] = mag_sum\n",
    "                continue\n",
    "            \n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(gray_prev, gray_next, p0, None, **lk_params)\n",
    "            \n",
    "            if p1 is not None:\n",
    "                good_new = p1[st == 1]  # Select good points\n",
    "                good_old = p0[st == 1]\n",
    "                \n",
    "            pts_diff = good_new - good_old\n",
    "            pts_mag = np.sqrt(pts_diff[:, 0] ** 2 + pts_diff[:, 1] ** 2)\n",
    "\n",
    "            pts_diff[pts_diff[:, 1] == 0, 1] = epsilon\n",
    "            pts_ang = np.int16(\n",
    "                np.round(np.arctan(pts_diff[:, 0] / pts_diff[:, 1]) * 180 / np.pi)\n",
    "            )\n",
    "           \n",
    "            img_next[np.where((img_next == [0, 0, 0]).all(axis=2))] = [255, 255, 255]\n",
    "            \n",
    "            # %%\n",
    "            img_prev = img_next.copy()\n",
    "            gray_prev = gray_next.copy()\n",
    "            area_prev = area_next\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "            #%%\n",
    "            df_das.loc[cnt3, \"area_next\"] = area_next\n",
    "            df_das.loc[cnt3, \"area_prev\"] = area_prev\n",
    "\n",
    "            mag_sum = np.sum(pts_mag)\n",
    "            mag_mean = 0\n",
    "\n",
    "            if mag_sum != 0:\n",
    "                mag_mean = np.mean(pts_mag)\n",
    "\n",
    "            df_das.loc[cnt3, \"mag_mean\"] = mag_mean\n",
    "            df_das.loc[cnt3, \"mag_sum\"] = mag_sum\n",
    "            \n",
    "        df_output = pd.concat([df_output, df_das.loc[0:len(df_das)- 2,: ]])\n",
    "        df_output.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    df_output.to_csv(os.path.join(csv_folder, folder_name + \".csv\"), index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6587a200",
   "metadata": {},
   "source": [
    "### Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_output = os.path.join(dirParent, 'Datasets', expID, expID + '_' + \"csv_output\")\n",
    "coor_df = pd.read_csv(coor_path)\n",
    "\n",
    "list_csv = [x for x in os.listdir(csv_folder) if (x[-3:]) == \"csv\"]\n",
    "df_csv = pd.DataFrame(list_csv, columns=[\"filename\"])\n",
    "df_csv[[\"position\",\"name\", \"treatment\"]] = df_csv[\"filename\"].str.split('_',expand=True)\n",
    "df_csv[\"treatment\"] = df_csv[\"treatment\"].apply(lambda x: x[:-4])\n",
    "outliers = coor_df.loc[coor_df[\"outlier\"] == \"yes\", \"position\"].tolist()\n",
    "\n",
    "if not os.path.exists(csv_output):\n",
    "    os.makedirs(csv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dec19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 0\n",
    "min_len = 100\n",
    "pixelSiz = 0.235\n",
    "\n",
    "for ecotype in df_csv.loc[:, \"name\"].unique():\n",
    "    \n",
    "    for treat in df_csv.loc[:, \"treatment\"].unique():\n",
    "        \n",
    "        df_rre = pd.DataFrame()\n",
    "        df_disp = pd.DataFrame()\n",
    "        \n",
    "        df_aux = df_csv[(df_csv[\"treatment\"]==treat) & (df_csv[\"name\"]==ecotype)].sort_values(by=\"position\")\n",
    "        df_aux.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        \n",
    "        for cnt in range(len(df_aux)):\n",
    "            timeFit, areaF, param, perr = [], [], [], []\n",
    "            filename, posn = df_aux.loc[cnt, [\"filename\", \"position\"]]\n",
    "            file_csv = pd.read_csv(os.path.join(csv_folder, filename))\n",
    "\n",
    "            if cnt == ref:\n",
    "                df_rre[\"date\"] = file_csv.loc[:, \"date\"]\n",
    "                \n",
    "                df_rre[\"mins\"] = file_csv[\"date\"].apply(lambda x: (datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\") - dateSowing\n",
    "                ).total_seconds()/ 60.0)\n",
    "                df_rre[\"das\"] = df_rre.loc[:, \"mins\"]/(60*24)\n",
    "                df_disp = df_rre.copy()\n",
    "            \n",
    "            if len(file_csv) != len(df_rre):             \n",
    "                continue\n",
    "            \n",
    "            timeFit, areaF = imalgo.fitting(df_rre.loc[:, \"mins\"].values, file_csv.loc[:, \"area_prev\"].values)\n",
    "            df_rre[posn] = (file_csv.loc[:, \"area_prev\"].values - areaF) * pixelSiz          \n",
    "            df_disp[posn] = file_csv.loc[:, \"mag_sum\"] * pixelSiz\n",
    "            \n",
    "            _das = np.unique(np.int16(np.floor(df_disp.loc[:, \"das\"].values)))\n",
    "            for cnt1 in range(len(_das) - 1):\n",
    "                df_das = []\n",
    "                df_das = df_disp.loc[(df_disp[\"das\"] >_das[cnt1]) & (df_disp[\"das\"] <_das[cnt1 +1]),  posn]\n",
    "                std_thr =  4 * df_das.std()\n",
    "                df_das[df_das > std_thr] = std_thr\n",
    "                df_disp.loc[(df_disp[\"das\"] >_das[cnt1]) & (df_disp[\"das\"] <_das[cnt1 +1]),  posn] = df_das.values\n",
    "            \n",
    "            name_out = ecotype + \"_\" + treat + \"_\"\n",
    "            df_rre.to_csv(os.path.join(csv_output, name_out + \"Rosette relative expansion\"+ \".csv\"), index=False)\n",
    "            df_disp.to_csv(os.path.join(csv_output, name_out + \"Displacement\"+ \".csv\"), index=False)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
